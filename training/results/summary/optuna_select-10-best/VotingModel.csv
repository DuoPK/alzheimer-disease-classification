dataset,model,best_params,final_test_results-accuracy,final_test_results-f1_score,final_test_results-training_time
impute_standard,VotingModel,"{""lr_C"": 2.454596477149783, ""lr_max_iter"": 100, ""gnb_var_smoothing"": 0.0008057516134971828, ""qda_reg_param"": 0.20387975671986416, ""voting_weight_lr"": 0.9643615551709674, ""voting_weight_gnb"": 1.7138292810414688, ""voting_weight_qda"": 1.441662100944638, ""voting"": ""hard""}",0.8407494145199064,0.7588652482269503,0.01265096664428711
mean_standard,VotingModel,"{""lr_C"": 58.51623793892882, ""lr_max_iter"": 1500, ""gnb_var_smoothing"": 2.852222240047648e-07, ""qda_reg_param"": 0.053749663475620824, ""voting_weight_lr"": 1.8414124521758644, ""voting_weight_gnb"": 0.1836613241362779, ""voting_weight_qda"": 1.8084349221476979, ""voting"": ""soft""}",0.8407494145199064,0.7605633802816901,0.012166976928710938
