dataset,model,best_params,final_test_results-accuracy,final_test_results-f1_score,final_test_results-training_time
impute_standard,VotingModel,"{""lr_C"": 22.264827020094533, ""lr_max_iter"": 1100, ""gnb_var_smoothing"": 2.798831431792034e-07, ""qda_reg_param"": 0.48892097016381997, ""voting_weight_lr"": 1.9971437063438988, ""voting_weight_gnb"": 0.9565311377561485, ""voting_weight_qda"": 1.2347473577200991, ""voting"": ""soft""}",0.8220140515222483,0.7266187050359713,0.012841463088989258
mean_standard,VotingModel,"{""lr_C"": 88.48617842194284, ""lr_max_iter"": 100, ""gnb_var_smoothing"": 1.3365107913512196e-07, ""qda_reg_param"": 0.2231460153712538, ""voting_weight_lr"": 1.9296801800408465, ""voting_weight_gnb"": 0.6967528590518568, ""voting_weight_qda"": 1.9866961856775054, ""voting"": ""soft""}",0.8266978922716628,0.7318840579710145,0.013060808181762695
